<!doctype html><html lang=en dir=auto><head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Load+Reload: Uma prova de conceito de um side-channel que explora a cache associativa de processadores AMD | Blog do GRIS</title>
<meta name=keywords content><meta name=description content="Introdução
Em busca da maior performance possível, os processadores atuais tiram
vantagem de diversos artifícios, muitas vezes sem grande consideração
pela segurança. Nesse contexto, ataques como Spectre (Kocher et al.
2019) e Meltdown (Lipp et al. 2018) mostram que a execução especulativa
é um tópico muito interessante a ser explorado. Nesse artigo,
construiremos uma prova de conceito do ataque Load+Reload (Lipp et al.
2020), que tira vantagem do preditor de way presente na cache dos
processadores atuais da AMD. Durante esse processo, veremos uma forma
diferente de medir o tempo de leitura da memória, a thread contadora,
mais precisa do que a instrução rdtsc, usada em ataques como
Flush+Reload (Yarom and Falkner 2014)."><meta name=author content="ottoboni"><link rel=canonical href=http://localhost:1313/2022-10-02-load+reload/><meta name=google-site-verification content="G-YWN8S4BKK0"><link crossorigin=anonymous href=/assets/css/stylesheet.45e028aa8ce0961349adf411b013ee39406be2c0bc80d4ea3fc04555f7f4611a.css integrity="sha256-ReAoqozglhNJrfQRsBPuOUBr4sC8gNTqP8BFVff0YRo=" rel="preload stylesheet" as=style><link rel=icon href=http://localhost:1313/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=16x16 href=http://localhost:1313/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=32x32 href=http://localhost:1313/%3Clink%20/%20abs%20url%3E><link rel=apple-touch-icon href=http://localhost:1313/%3Clink%20/%20abs%20url%3E><link rel=mask-icon href=http://localhost:1313/%3Clink%20/%20abs%20url%3E><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=http://localhost:1313/2022-10-02-load+reload/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:url" content="http://localhost:1313/2022-10-02-load+reload/"><meta property="og:site_name" content="Blog do GRIS"><meta property="og:title" content="Load+Reload: Uma prova de conceito de um side-channel que explora a cache associativa de processadores AMD"><meta property="og:description" content="Introdução Em busca da maior performance possível, os processadores atuais tiram vantagem de diversos artifícios, muitas vezes sem grande consideração pela segurança. Nesse contexto, ataques como Spectre (Kocher et al. 2019) e Meltdown (Lipp et al. 2018) mostram que a execução especulativa é um tópico muito interessante a ser explorado. Nesse artigo, construiremos uma prova de conceito do ataque Load+Reload (Lipp et al. 2020), que tira vantagem do preditor de way presente na cache dos processadores atuais da AMD. Durante esse processo, veremos uma forma diferente de medir o tempo de leitura da memória, a thread contadora, mais precisa do que a instrução rdtsc, usada em ataques como Flush+Reload (Yarom and Falkner 2014)."><meta property="og:locale" content="pt"><meta property="og:type" content="article"><meta property="article:published_time" content="2022-10-02T00:00:00+00:00"><meta property="article:modified_time" content="2022-10-02T00:00:00+00:00"><meta property="og:image" content="http://localhost:1313/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="http://localhost:1313/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="Load+Reload: Uma prova de conceito de um side-channel que explora a cache associativa de processadores AMD"><meta name=twitter:description content="Introdução
Em busca da maior performance possível, os processadores atuais tiram
vantagem de diversos artifícios, muitas vezes sem grande consideração
pela segurança. Nesse contexto, ataques como Spectre (Kocher et al.
2019) e Meltdown (Lipp et al. 2018) mostram que a execução especulativa
é um tópico muito interessante a ser explorado. Nesse artigo,
construiremos uma prova de conceito do ataque Load+Reload (Lipp et al.
2020), que tira vantagem do preditor de way presente na cache dos
processadores atuais da AMD. Durante esse processo, veremos uma forma
diferente de medir o tempo de leitura da memória, a thread contadora,
mais precisa do que a instrução rdtsc, usada em ataques como
Flush+Reload (Yarom and Falkner 2014)."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Load+Reload: Uma prova de conceito de um side-channel que explora a cache associativa de processadores AMD","item":"http://localhost:1313/2022-10-02-load+reload/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Load+Reload: Uma prova de conceito de um side-channel que explora a cache associativa de processadores AMD","name":"Load\u002bReload: Uma prova de conceito de um side-channel que explora a cache associativa de processadores AMD","description":"Introdução Em busca da maior performance possível, os processadores atuais tiram vantagem de diversos artifícios, muitas vezes sem grande consideração pela segurança. Nesse contexto, ataques como Spectre (Kocher et al. 2019) e Meltdown (Lipp et al. 2018) mostram que a execução especulativa é um tópico muito interessante a ser explorado. Nesse artigo, construiremos uma prova de conceito do ataque Load+Reload (Lipp et al. 2020), que tira vantagem do preditor de way presente na cache dos processadores atuais da AMD. Durante esse processo, veremos uma forma diferente de medir o tempo de leitura da memória, a thread contadora, mais precisa do que a instrução rdtsc, usada em ataques como Flush+Reload (Yarom and Falkner 2014).\n","keywords":[],"articleBody":"Introdução Em busca da maior performance possível, os processadores atuais tiram vantagem de diversos artifícios, muitas vezes sem grande consideração pela segurança. Nesse contexto, ataques como Spectre (Kocher et al. 2019) e Meltdown (Lipp et al. 2018) mostram que a execução especulativa é um tópico muito interessante a ser explorado. Nesse artigo, construiremos uma prova de conceito do ataque Load+Reload (Lipp et al. 2020), que tira vantagem do preditor de way presente na cache dos processadores atuais da AMD. Durante esse processo, veremos uma forma diferente de medir o tempo de leitura da memória, a thread contadora, mais precisa do que a instrução rdtsc, usada em ataques como Flush+Reload (Yarom and Falkner 2014).\nOrganização interna da cache A cache de um processador é uma memória que armazena páginas de memória recentemente acessadas. Por na maior parte das vezes ser composta por células de memória estáticas (SRAM), a cache é múltiplas vezes mais rápida que a memória principal de um computador, que usa células dinâmicas (DRAM).\nA menor unidade dentro da cache é chamada de linha e geralmente tem o mesmo tamanho de uma página de memória. Uma certa página, no entanto, não necessariamente pode ser armazenada em qualquer linha. O grupo de linhas nas quais uma página pode ser amazenada é chamada de set. Além disso, cada linha de um set onde uma certa página pode ser armazenada é chamada de way.\nNo caso mais simples, cada set tem apenas 1 way e a cache é considerada diretamente mapeada, pois cada página só pode ser armazenada em exatamente uma linha. Se, pelo contrário, uma página pode ser armazenada em qualquer linha, a cache é considerada totalmente associativa, como se tivesse apenas 1 grande set. Por fim, se uma página pode ser armazenada em n linhas, a cache é considerada associativa por conjunto n-way.\nOutro ponto importante é a forma como a cache será indexada e marcada. O index se refere ao endereço utilizado para acessar um certo set, enquanto que a marca[1] se refere a como cada way dentro de um set será identificado. Nos processadores Zen da AMD, a cache é virtualmente indexada e fisicamente marcada (VIPT)[2](AMD 2019). Isso significa que a partir do endereço virtual de uma página é possível encontrar o set onde ela está armazenada na cache. Analogamente, a partir do endereço físico de uma página é possível encontrar em qual way do set página está.\nPredição de way Como explicado no tópico anterior, quando uma página de memória é requisitada, primeiro o endereço virtual dela é utilizado para determinar o set da cache onde ela pode estar armazenada. Após determinar o set, o endereço físico é utilizado para encontrar o way. A grande vantagem desse método é que o endereço físico pode ser calculado enquanto o set está sendo determinado.\nNa arquitetura Zen da AMD, a cache L1 de dados é associativa por conjunto 8-way(AMD 2019), ou seja, pode ser necessário verificar a marca de 8 ways para saber em qual deles uma página pode estar armazenada. A fim de acelerar esse processo, o processador usa uma μmarca para determinar se a página está ou não em um set(AMD 2019). A μmarca é uma função do endereço virtual e, analogamente à marca normal, fica armazenada em cada way. Como ela não depende do endereço físico, o processador pode rapidamente verificar se algum way tem a μmarca correspondente e, se nenhum tiver, imediamente desistir da cache L1 e começar a procurar a página na cache L2, sem nem mesmo esperar a tradução do endereço virtual para o físico.\nO problema ocorre quando dois endereços virtuais distintos referentes ao mesmo endereço físico são acessados em sucessão. Cada acesso vai alterar a μmarca, fazendo com que o próximo acesso caia para a cache L2, já que o preditor de way não encontrará a μmarca que foi sobrescrita(AMD 2019). Nesse caso, todos os acessos serão feitos na cache L2, aumentando o tempo de acesso.\nAtaques de cache Um side-channel se baseia em extrair informação por meio de algum rastro deixado pela implementação de um sistema. A cache de um processador, por exemplo, implicitamente informa um processo se uma certa página de memória foi acessada recentemente.\nSe dois processos A e B compartilham a mesma página de memória, o processo B pode medir o tempo gasto para ler a página e determinar se a mesma está ou não na cache. Caso a leitura seja rápida, a página estava na cache; caso contrário, não estava. Dessa forma, se o processo B sabe que a página não estava na cache em um momento t1 e em um momento posterior t2 for determinado que a página estava na cache, pode-se concluir que o processo A a acessou.\nMedindo o tempo de acesso rdtsc No artigo original do ataque Flush+Reload (Yarom and Falkner 2014), a instrução rdtsc é utilizada para pedir o tempo de acesso à memória e determinar se uma certa página está ou não na cache. Essa instrução carrega o valor do time-stamp counter nos registradores edx:eax. Assim, em conjunto com instruções de ordenação de execução, é possível calcular o tempo decorrido entre o início e fim da leitura.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 //Função que calcula o tempo de acesso a uma página usando a instrução uint64_t load_count(uint64_t *addr) { uint64_t volatile time; asm volatile ( \"mfence \\n\\t\" \"lfence \\n\\t\" \"rdtsc \\n\\t\" \"lfence \\n\\t\" \"movl %%eax, %%ebx \\n\\t\" \"movq (%%rcx), %%rcx \\n\\t\" \"lfence \\n\\t\" \"rdtsc \\n\\t\" \"subl %%ebx, %%eax \\n\\t\" : \"=a\" (time) : \"c\" (addr) : \"rbx\" ); return time; } Função que calcula o tempo de acesso a uma página usando a instrução \\texttt{rdtsc}\nUm problema ao usar a instrução rdtsc é que nos processadores mais recentes da AMD ela não é mais tão precisa, pois tem seu contador incrementado a cada 30 ciclos aproximadamente (Lipp et al. 2020). Esse fato diminui muito a resolução da medição, principalmente em ataques nos quais a diferença do tempo de acesso é mais sutil.\nA thread contadora 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 //Função da thread contadora uint64_t volatile count = 0; void *counting_thread(void *args) { set_affinity(COUNTING_CORE); asm volatile ( \"xorq %%rax, %%rax \\n\\t\" \"loop%=: \\n\\t\" \"incq %%rax \\n\\t\" \"movq %%rax, (%%rbx) \\n\\t\" \"jmp loop%= \\n\\t\" : : \"b\" (\u0026count) : \"rax\" ); pthread_exit(NULL); } O artigo ARMageddon (Lipp et al. 2016) mostrou que threads contadoras podem ter uma resolução tão boa ou melhor do que a instrução rdtsc em processadores ARM. A ideia é ter uma thread cujo único objetivo é incrementar uma variável global continuamente o mais rápido possível.\nA fim de ser o mais otimizada possível, a thread contadora armazena o valor atual de count no registrador rax e o copia para a memória após incrementá-la. Dessa forma, apenas uma escrita à memória é realizada e o valor atual é acessado exclusivamente pelo registrador.\nUm ponto importante a ser notado no código da thread contadora é o uso das instruções de ordenação mfence e lfence. Analogamente à medição do tempo usando a instrução rdtsc, é necessário garantir que as duas leituras à variável count aconteçam antes e depois da leitura da página. Além disso, para o caso da thread contadora, é importante que a thread principal do atacante obtenha um valor minimamente atualizado de count. A seguir está reproduzido um trecho do manual da Intel sobre a instrução mfence.\nThis serializing operation guarantees that every load and store instruction that precedes the MFENCE instruction in program order becomes globally visible before any load or store instruction that follows the MFENCE instruction.\n(Intel 2021)\nDessa forma, segundo o manual, os incrementos realizados pela thread contadora na variável count durante a leitura da página se tornarão visíveis globalmente antes da segunda leitura de count que segue a instrução mfence. O uso dessa instrução é fundamental, pois sem ela as duas leituras de count retornariam o mesmo valor na maior parte das vezes, o que resultaria em um tempo de leitura nulo.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 //Função que calcula o tempo de acesso a uma página usando a thread contadora. uint64_t load_count(uint64_t *addr) { uint64_t volatile time; asm volatile ( \"mfence \\n\\t\" \"lfence \\n\\t\" \"movq (%%rbx), %%rcx \\n\\t\" \"lfence \\n\\t\" \"movq (%%rax), %%rdx \\n\\t\" \"lfence \\n\\t\" \"mfence \\n\\t\" \"movq (%%rbx), %%rax \\n\\t\" \"subq %%rcx, %%rax \\n\\t\" : \"=a\" (time) : \"a\" (addr), \"b\" (\u0026count) : \"rcx\", \"rdx\" ); return time; } Load+Reload Load+Reload é um dos dois ataques propostos no artigo Take a Way(Lipp et al. 2020) e tira vantagem do fato que quando dois endereços virtuais distintos referentes ao mesmo endereço físico são acessados em sucessão, a leitura ocorrerá na cache L2. Esse comportamento, entretanto, só ocorre quando as threads sendo executadas estão no mesmo núcleo físico(Lipp et al. 2020).\nForam então criados dois programas, uma vítima e um atacante, que serão executados em núcleos lógicos distintos, mas no mesmo núcleo físico. Para isso, foi utilizada a biblioteca pthread para criar a thread e prendê-la a um núcleo específico.\nA memória que será compartilhada entre a vítima e o atacante é um arquivo de 8MiB composto de bytes aleatórios mapeados na memória com a syscall nmap. O ataque consiste em uma vítima lendo continuamente partes do arquivo data usando caracteres de uma string secret. O caractere é multiplicado por 4096, de modo que cada byte do arquivo lido está em uma página distinta.\n1 2 //Leitura do arquivo a partir da string secret. read_byte(\u0026data[secret[i] * 4096]); Enquanto isso, o atacante também lê continuamente o arquivo. Diferente da vítima, no entanto, o atacante selectiona todos os bytes de 0 até 0xff como índice para a leitura do arquivo.\n1 2 uint64_t time = load_count(\u0026data[byte * 4096]); O tempo levado para a leitura é então medido usando uma thread contadora e o byte que levou mais tempo para ser lido é escolhido como o que a vítima estava lendo naquele momento.\nA ideia é que se o byte sendo lido pelo atacante for o mesmo que está sendo lido pela vítima, a leitura do atacante cairá para a L2 por conta do preditor de way. Essa leitura na L2 levará consideravelmente mais tempo do que uma leitura na L1, e essa diferença pode ser medida usando a thread contadora.\n[1] Tag em inglês.\n[2] Virtually indexed and physically tagged (VIPT) em inglês.\nCódigo fonte https://github.com/grisufrj/articles/tree/main/load%2Breload\nBibliografia AMD. 2019. Software Optimization Guide for AMD Family 17h Models 30h and Greater Processors. https://developer.amd.com/wp-content/resources/56305_SOG_3.00_PUB.pdf.\nIntel. 2021. Intel® 64 and IA-32 Architectures Software Developer’s Manual. https://cdrdv2.intel.com/v1/dl/getContent/671200.\nKocher, Paul, Jann Horn, Anders Fogh, Daniel Genkin, Daniel Gruss, Werner Haas, Mike Hamburg, et al. 2019. “Spectre Attacks: Exploiting Speculative Execution.” In 2019 IEEE Symposium on Security and Privacy (SP), 1–19. https://doi.org/10.1109/SP.2019.00002.\nLipp, Moritz, Daniel Gruss, Raphael Spreitzer, Clémentine Maurice, and Stefan Mangard. 2016. “ARMageddon: Cache Attacks on Mobile Devices.” In 25th USENIX Security Symposium (USENIX Security 16), 549–64. Austin, TX: USENIX Association. https://www.usenix.org/conference/usenixsecurity16/technical-sessions/presentation/lipp.\nLipp, Moritz, Vedad Hadžić, Michael Schwarz, Arthur Perais, Clémentine Maurice, and Daniel Gruss. 2020. “Take A Way: Exploring the Security Implications of AMD’s Cache Way Predictors.” In 15th ACM ASIA Conference on Computer and Communications Security (ACM ASIACCS 2020). Taipei, Taiwan. https://doi.org/10.1145/3320269.3384746.\nLipp, Moritz, Michael Schwarz, Daniel Gruss, Thomas Prescher, Werner Haas, Anders Fogh, Jann Horn, et al. 2018. “Meltdown: Reading Kernel Memory from User Space.” In 27th USENIX Security Symposium (USENIX Security 18), 973–90. Baltimore, MD: USENIX Association. https://www.usenix.org/conference/usenixsecurity18/presentation/lipp.\nYarom, Yuval, and Katrina Falkner. 2014. “FLUSH+RELOAD: A High Resolution, Low Noise, L3 Cache Side-Channel Attack.” In 23rd USENIX Security Symposium (USENIX Security 14), 719–32. San Diego, CA: USENIX Association. https://www.usenix.org/conference/usenixsecurity14/technical-sessions/presentation/yarom.\n","wordCount":"1957","inLanguage":"en","image":"http://localhost:1313/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E","datePublished":"2022-10-02T00:00:00Z","dateModified":"2022-10-02T00:00:00Z","author":{"@type":"Person","name":"ottoboni"},"mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:1313/2022-10-02-load+reload/"},"publisher":{"@type":"Organization","name":"Blog do GRIS","logo":{"@type":"ImageObject","url":"http://localhost:1313/%3Clink%20/%20abs%20url%3E"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=http://localhost:1313/ accesskey=h title="Home (Alt + H)"><img src=http://localhost:1313/apple-touch-icon.png alt aria-label=logo height=35>Home</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=http://localhost:1313/categories/ title=Categorias><span>Categorias</span></a></li><li><a href=http://localhost:1313/tags/ title=Tags><span>Tags</span></a></li><li><a href=https://www.youtube.com/@grisufrj title=Youtube><span>Youtube</span>&nbsp;<svg fill="none" shape-rendering="geometricPrecision" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12"><path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"/><path d="M15 3h6v6"/><path d="M10 14 21 3"/></svg></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=http://localhost:1313/>Home</a></div><h1 class="post-title entry-hint-parent">Load+Reload: Uma prova de conceito de um side-channel que explora a cache associativa de processadores AMD</h1><div class=post-meta><span title='2022-10-02 00:00:00 +0000 UTC'>October 2, 2022</span>&nbsp;·&nbsp;10 min&nbsp;·&nbsp;1957 words&nbsp;·&nbsp;ottoboni&nbsp;|&nbsp;<a href=https://github.com/%3cpath_to_repo%3e/content/2022-10-02-Load+Reload.md rel="noopener noreferrer" target=_blank>Suggest Changes</a></div></header><div class=post-content><h1 id=introdução>Introdução<a hidden class=anchor aria-hidden=true href=#introdução>#</a></h1><p>Em busca da maior performance possível, os processadores atuais tiram
vantagem de diversos artifícios, muitas vezes sem grande consideração
pela segurança. Nesse contexto, ataques como Spectre (Kocher et al.
2019) e Meltdown (Lipp et al. 2018) mostram que a execução especulativa
é um tópico muito interessante a ser explorado. Nesse artigo,
construiremos uma prova de conceito do ataque Load+Reload (Lipp et al.
2020), que tira vantagem do preditor de <em>way</em> presente na cache dos
processadores atuais da AMD. Durante esse processo, veremos uma forma
diferente de medir o tempo de leitura da memória, a thread contadora,
mais precisa do que a instrução <code>rdtsc</code>, usada em ataques como
Flush+Reload (Yarom and Falkner 2014).</p><h1 id=organização-interna-da-cache>Organização interna da cache<a hidden class=anchor aria-hidden=true href=#organização-interna-da-cache>#</a></h1><p>A cache de um processador é uma memória que armazena páginas de memória
recentemente acessadas. Por na maior parte das vezes ser composta por
células de memória estáticas (SRAM), a cache é múltiplas vezes mais
rápida que a memória principal de um computador, que usa células
dinâmicas (DRAM).</p><p>A menor unidade dentro da cache é chamada de <strong>linha</strong> e geralmente tem
o mesmo tamanho de uma página de memória. Uma certa página, no entanto,
não necessariamente pode ser armazenada em qualquer linha. O grupo de
linhas nas quais uma página pode ser amazenada é chamada de <strong>set</strong>.
Além disso, cada linha de um set onde uma certa página pode ser
armazenada é chamada de <strong>way</strong>.</p><p>No caso mais simples, cada set tem apenas 1 way e a cache é considerada
<strong>diretamente mapeada</strong>, pois cada página só pode ser armazenada em
exatamente uma linha. Se, pelo contrário, uma página pode ser armazenada
em <em>qualquer</em> linha, a cache é considerada <strong>totalmente associativa</strong>,
como se tivesse apenas 1 grande set. Por fim, se uma página pode ser
armazenada em <em>n</em> linhas, a cache é considerada <strong>associativa por
conjunto <em>n</em>-way</strong>.</p><p>Outro ponto importante é a forma como a cache será indexada e marcada. O
<strong>index</strong> se refere ao endereço utilizado para acessar um certo set,
enquanto que a <strong>marca</strong>[1] se refere a como cada way dentro de um set
será identificado. Nos processadores Zen da AMD, a cache é
<strong>virtualmente indexada e fisicamente marcada (VIPT)</strong>[2](AMD 2019).
Isso significa que a partir do endereço virtual de uma página é possível
encontrar o set onde ela está armazenada na cache. Analogamente, a
partir do endereço físico de uma página é possível encontrar em qual way
do set página está.</p><h1 id=predição-de-way>Predição de way<a hidden class=anchor aria-hidden=true href=#predição-de-way>#</a></h1><p>Como explicado no tópico anterior, quando uma página de memória é
requisitada, primeiro o endereço virtual dela é utilizado para
determinar o set da cache onde ela pode estar armazenada. Após
determinar o set, o endereço físico é utilizado para encontrar o way. A
grande vantagem desse método é que o endereço físico pode ser calculado
enquanto o set está sendo determinado.</p><p>Na arquitetura Zen da AMD, a cache L1 de dados é associativa por
conjunto 8-way(AMD 2019), ou seja, pode ser necessário verificar a marca
de 8 ways para saber em qual deles uma página pode estar armazenada. A
fim de acelerar esse processo, o processador usa uma <em>μ</em>marca para
determinar se a página está ou não em um set(AMD 2019). A <em>μ</em>marca é uma
função do endereço virtual e, analogamente à marca normal, fica
armazenada em cada way. Como ela não depende do endereço físico, o
processador pode rapidamente verificar se algum way tem a <em>μ</em>marca
correspondente e, se nenhum tiver, imediamente desistir da cache L1 e
começar a procurar a página na cache L2, sem nem mesmo esperar a
tradução do endereço virtual para o físico.</p><p>O problema ocorre quando dois endereços virtuais <em>distintos</em> referentes
ao <em>mesmo</em> endereço físico são acessados em sucessão. Cada acesso vai
alterar a <em>μ</em>marca, fazendo com que o próximo acesso caia para a cache
L2, já que o preditor de way não encontrará a <em>μ</em>marca que foi
sobrescrita(AMD 2019). Nesse caso, todos os acessos serão feitos na
cache L2, aumentando o tempo de acesso.</p><h1 id=ataques-de-cache>Ataques de cache<a hidden class=anchor aria-hidden=true href=#ataques-de-cache>#</a></h1><p>Um side-channel se baseia em extrair informação por meio de algum rastro
deixado pela implementação de um sistema. A cache de um processador, por
exemplo, implicitamente informa um processo se uma certa página de
memória foi acessada recentemente.</p><p>Se dois processos <em>A</em> e <em>B</em> compartilham a mesma página de memória, o
processo <em>B</em> pode medir o tempo gasto para ler a página e determinar se
a mesma está ou não na cache. Caso a leitura seja rápida, a página
estava na cache; caso contrário, não estava. Dessa forma, se o processo
<em>B</em> sabe que a página não estava na cache em um momento <em>t</em>1
e em um momento posterior <em>t</em>2 for determinado que a página
estava na cache, pode-se concluir que o processo <em>A</em> a acessou.</p><h1 id=medindo-o-tempo-de-acesso>Medindo o tempo de acesso<a hidden class=anchor aria-hidden=true href=#medindo-o-tempo-de-acesso>#</a></h1><h2 id=rdtsc><code>rdtsc</code><a hidden class=anchor aria-hidden=true href=#rdtsc>#</a></h2><p>No artigo original do ataque Flush+Reload (Yarom and Falkner 2014), a
instrução <code>rdtsc</code> é utilizada para pedir o tempo de acesso à memória e
determinar se uma certa página está ou não na cache. Essa instrução
carrega o valor do <em>time-stamp counter</em> nos registradores <code>edx:eax</code>.
Assim, em conjunto com instruções de ordenação de execução, é possível
calcular o tempo decorrido entre o início e fim da leitura.</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-.c data-lang=.c><span class=line><span class=cl><span class=c1>//Função que calcula o tempo de acesso a uma página usando a instrução
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=kt>uint64_t</span> <span class=nf>load_count</span><span class=p>(</span><span class=kt>uint64_t</span> <span class=o>*</span><span class=n>addr</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=p>{</span>
</span></span><span class=line><span class=cl>	<span class=kt>uint64_t</span> <span class=k>volatile</span> <span class=n>time</span><span class=p>;</span>
</span></span><span class=line><span class=cl>	<span class=k>asm</span> <span class=k>volatile</span> <span class=p>(</span>
</span></span><span class=line><span class=cl>		<span class=s>&#34;mfence              </span><span class=se>\n\t</span><span class=s>&#34;</span>
</span></span><span class=line><span class=cl>		<span class=s>&#34;lfence              </span><span class=se>\n\t</span><span class=s>&#34;</span>
</span></span><span class=line><span class=cl>		<span class=s>&#34;rdtsc               </span><span class=se>\n\t</span><span class=s>&#34;</span>
</span></span><span class=line><span class=cl>		<span class=s>&#34;lfence              </span><span class=se>\n\t</span><span class=s>&#34;</span>
</span></span><span class=line><span class=cl>		<span class=s>&#34;movl %%eax, %%ebx   </span><span class=se>\n\t</span><span class=s>&#34;</span>
</span></span><span class=line><span class=cl>		<span class=s>&#34;movq (%%rcx), %%rcx </span><span class=se>\n\t</span><span class=s>&#34;</span>
</span></span><span class=line><span class=cl>		<span class=s>&#34;lfence              </span><span class=se>\n\t</span><span class=s>&#34;</span>
</span></span><span class=line><span class=cl>		<span class=s>&#34;rdtsc               </span><span class=se>\n\t</span><span class=s>&#34;</span>
</span></span><span class=line><span class=cl>		<span class=s>&#34;subl %%ebx, %%eax   </span><span class=se>\n\t</span><span class=s>&#34;</span>
</span></span><span class=line><span class=cl>		<span class=o>:</span> <span class=s>&#34;=a&#34;</span> <span class=p>(</span><span class=n>time</span><span class=p>)</span>
</span></span><span class=line><span class=cl>		<span class=o>:</span> <span class=s>&#34;c&#34;</span> <span class=p>(</span><span class=n>addr</span><span class=p>)</span>
</span></span><span class=line><span class=cl>		<span class=o>:</span> <span class=s>&#34;rbx&#34;</span>
</span></span><span class=line><span class=cl>	<span class=p>);</span>
</span></span><span class=line><span class=cl>	<span class=k>return</span> <span class=n>time</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></td></tr></table></div></div><p>Função que calcula o tempo de acesso a uma página usando a instrução \texttt{rdtsc}</p><p>Um problema ao usar a instrução <code>rdtsc</code> é que nos processadores mais
recentes da AMD ela não é mais tão precisa, pois tem seu contador
incrementado a cada 30 ciclos aproximadamente (Lipp et al. 2020). Esse
fato diminui muito a resolução da medição, principalmente em ataques nos
quais a diferença do tempo de acesso é mais sutil.</p><h2 id=a-thread-contadora>A thread contadora<a hidden class=anchor aria-hidden=true href=#a-thread-contadora>#</a></h2><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-.c data-lang=.c><span class=line><span class=cl><span class=c1>//Função da thread contadora
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=kt>uint64_t</span> <span class=k>volatile</span> <span class=n>count</span> <span class=o>=</span> <span class=mi>0</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=kt>void</span> <span class=o>*</span><span class=nf>counting_thread</span><span class=p>(</span><span class=kt>void</span> <span class=o>*</span><span class=n>args</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>	<span class=nf>set_affinity</span><span class=p>(</span><span class=n>COUNTING_CORE</span><span class=p>);</span>
</span></span><span class=line><span class=cl>	<span class=k>asm</span> <span class=k>volatile</span> <span class=p>(</span>
</span></span><span class=line><span class=cl>		<span class=s>&#34;xorq %%rax, %%rax   </span><span class=se>\n\t</span><span class=s>&#34;</span>
</span></span><span class=line><span class=cl>		<span class=s>&#34;loop%=:             </span><span class=se>\n\t</span><span class=s>&#34;</span>
</span></span><span class=line><span class=cl>		<span class=s>&#34;incq %%rax          </span><span class=se>\n\t</span><span class=s>&#34;</span>
</span></span><span class=line><span class=cl>		<span class=s>&#34;movq %%rax, (%%rbx) </span><span class=se>\n\t</span><span class=s>&#34;</span>
</span></span><span class=line><span class=cl>		<span class=s>&#34;jmp loop%=          </span><span class=se>\n\t</span><span class=s>&#34;</span>
</span></span><span class=line><span class=cl>		<span class=o>:</span>
</span></span><span class=line><span class=cl>		<span class=o>:</span> <span class=s>&#34;b&#34;</span> <span class=p>(</span><span class=o>&amp;</span><span class=n>count</span><span class=p>)</span>
</span></span><span class=line><span class=cl>		<span class=o>:</span> <span class=s>&#34;rax&#34;</span>
</span></span><span class=line><span class=cl>	<span class=p>);</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>	<span class=nf>pthread_exit</span><span class=p>(</span><span class=nb>NULL</span><span class=p>);</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></td></tr></table></div></div><p>O artigo ARMageddon (Lipp et al. 2016) mostrou que threads contadoras
podem ter uma resolução tão boa ou melhor do que a instrução <code>rdtsc</code> em
processadores ARM. A ideia é ter uma thread cujo único objetivo é
incrementar uma variável global continuamente o mais rápido possível.</p><p>A fim de ser o mais otimizada possível, a thread contadora armazena o
valor atual de <code>count</code> no registrador <code>rax</code> e o copia para a memória
após incrementá-la. Dessa forma, apenas uma escrita à memória é
realizada e o valor atual é acessado exclusivamente pelo registrador.</p><p>Um ponto importante a ser notado no código da thread contadora é o uso
das instruções de ordenação <code>mfence</code> e <code>lfence</code>. Analogamente à medição
do tempo usando a instrução <code>rdtsc</code>, é necessário garantir que as duas
leituras à variável <code>count</code> aconteçam antes e depois da leitura da
página. Além disso, para o caso da thread contadora, é importante que a
thread principal do atacante obtenha um valor minimamente atualizado de
<code>count</code>. A seguir está reproduzido um trecho do manual da Intel sobre a
instrução <code>mfence</code>.</p><blockquote><p>This serializing operation guarantees that every load and store
instruction that precedes the MFENCE instruction in program order
becomes globally visible before any load or store instruction that
follows the MFENCE instruction.</p><p>(Intel 2021)</p></blockquote><p>Dessa forma, segundo o manual, os incrementos realizados pela thread
contadora na variável <code>count</code> durante a leitura da página se tornarão
visíveis globalmente antes da segunda leitura de <code>count</code> que segue a
instrução <code>mfence</code>. O uso dessa instrução é fundamental, pois sem ela as
duas leituras de <code>count</code> retornariam o mesmo valor na maior parte das
vezes, o que resultaria em um tempo de leitura nulo.</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-.c data-lang=.c><span class=line><span class=cl><span class=c1>//Função que calcula o tempo de acesso a uma página usando a thread contadora.
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=kt>uint64_t</span> <span class=nf>load_count</span><span class=p>(</span><span class=kt>uint64_t</span> <span class=o>*</span><span class=n>addr</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=p>{</span>
</span></span><span class=line><span class=cl>	<span class=kt>uint64_t</span> <span class=k>volatile</span> <span class=n>time</span><span class=p>;</span>
</span></span><span class=line><span class=cl>	<span class=k>asm</span> <span class=k>volatile</span> <span class=p>(</span>
</span></span><span class=line><span class=cl>		<span class=s>&#34;mfence              </span><span class=se>\n\t</span><span class=s>&#34;</span>
</span></span><span class=line><span class=cl>		<span class=s>&#34;lfence              </span><span class=se>\n\t</span><span class=s>&#34;</span>
</span></span><span class=line><span class=cl>		<span class=s>&#34;movq (%%rbx), %%rcx </span><span class=se>\n\t</span><span class=s>&#34;</span>
</span></span><span class=line><span class=cl>		<span class=s>&#34;lfence              </span><span class=se>\n\t</span><span class=s>&#34;</span>
</span></span><span class=line><span class=cl>		<span class=s>&#34;movq (%%rax), %%rdx </span><span class=se>\n\t</span><span class=s>&#34;</span>
</span></span><span class=line><span class=cl>		<span class=s>&#34;lfence              </span><span class=se>\n\t</span><span class=s>&#34;</span>
</span></span><span class=line><span class=cl>		<span class=s>&#34;mfence              </span><span class=se>\n\t</span><span class=s>&#34;</span>
</span></span><span class=line><span class=cl>		<span class=s>&#34;movq (%%rbx), %%rax </span><span class=se>\n\t</span><span class=s>&#34;</span>
</span></span><span class=line><span class=cl>		<span class=s>&#34;subq %%rcx, %%rax   </span><span class=se>\n\t</span><span class=s>&#34;</span>
</span></span><span class=line><span class=cl>		<span class=o>:</span> <span class=s>&#34;=a&#34;</span> <span class=p>(</span><span class=n>time</span><span class=p>)</span>
</span></span><span class=line><span class=cl>		<span class=o>:</span> <span class=s>&#34;a&#34;</span> <span class=p>(</span><span class=n>addr</span><span class=p>),</span> <span class=s>&#34;b&#34;</span> <span class=p>(</span><span class=o>&amp;</span><span class=n>count</span><span class=p>)</span>
</span></span><span class=line><span class=cl>		<span class=o>:</span> <span class=s>&#34;rcx&#34;</span><span class=p>,</span> <span class=s>&#34;rdx&#34;</span>
</span></span><span class=line><span class=cl>	<span class=p>);</span>
</span></span><span class=line><span class=cl>	<span class=k>return</span> <span class=n>time</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></td></tr></table></div></div><h1 id=loadreload>Load+Reload<a hidden class=anchor aria-hidden=true href=#loadreload>#</a></h1><p>Load+Reload é um dos dois ataques propostos no artigo Take a Way(Lipp et
al. 2020) e tira vantagem do fato que quando dois endereços virtuais
<em>distintos</em> referentes ao <em>mesmo</em> endereço físico são acessados em
sucessão, a leitura ocorrerá na cache L2. Esse comportamento,
entretanto, só ocorre quando as threads sendo executadas estão no mesmo
núcleo físico(Lipp et al. 2020).</p><p>Foram então criados dois programas, uma vítima e um atacante, que serão
executados em núcleos lógicos distintos, mas no mesmo núcleo físico.
Para isso, foi utilizada a biblioteca <code>pthread</code> para criar a thread e
prendê-la a um núcleo específico.</p><p>A memória que será compartilhada entre a vítima e o atacante é um
arquivo de 8MiB composto de bytes aleatórios mapeados na memória com a
syscall <code>nmap</code>. O ataque consiste em uma vítima lendo continuamente
partes do arquivo <code>data</code> usando caracteres de uma string <code>secret</code>. O
caractere é multiplicado por 4096, de modo que cada byte do arquivo lido
está em uma página distinta.</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-.c data-lang=.c><span class=line><span class=cl><span class=c1>//Leitura do arquivo a partir da string secret.
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=nf>read_byte</span><span class=p>(</span><span class=o>&amp;</span><span class=n>data</span><span class=p>[</span><span class=n>secret</span><span class=p>[</span><span class=n>i</span><span class=p>]</span> <span class=o>*</span> <span class=mi>4096</span><span class=p>]);</span>
</span></span></code></pre></td></tr></table></div></div><p>Enquanto isso, o atacante também lê continuamente o arquivo. Diferente
da vítima, no entanto, o atacante selectiona todos os bytes de <code>0</code> até
<code>0xff</code> como índice para a leitura do arquivo.</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-.c data-lang=.c><span class=line><span class=cl><span class=kt>uint64_t</span> <span class=n>time</span> <span class=o>=</span>
</span></span><span class=line><span class=cl>    <span class=nf>load_count</span><span class=p>(</span><span class=o>&amp;</span><span class=n>data</span><span class=p>[</span><span class=n>byte</span> <span class=o>*</span> <span class=mi>4096</span><span class=p>]);</span>
</span></span></code></pre></td></tr></table></div></div><p>O tempo levado para a leitura é então medido usando uma thread contadora
e o byte que levou mais tempo para ser lido é escolhido como o que a
vítima estava lendo naquele momento.</p><p>A ideia é que se o byte sendo lido pelo atacante for o mesmo que está
sendo lido pela vítima, a leitura do atacante cairá para a L2 por conta
do preditor de way. Essa leitura na L2 levará consideravelmente mais
tempo do que uma leitura na L1, e essa diferença pode ser medida usando
a thread contadora.</p><p>[1] <em>Tag</em> em inglês.</p><p>[2] <em>Virtually indexed and physically tagged (VIPT)</em> em inglês.</p><h2 id=código-fonte>Código fonte<a hidden class=anchor aria-hidden=true href=#código-fonte>#</a></h2><p><a href=https://github.com/grisufrj/articles/tree/main/load%2Breload>https://github.com/grisufrj/articles/tree/main/load%2Breload</a></p><h2 id=bibliografia>Bibliografia<a hidden class=anchor aria-hidden=true href=#bibliografia>#</a></h2><p>AMD. 2019. <em>Software Optimization Guide for AMD Family 17h Models 30h
and Greater Processors</em>.
<a href=https://developer.amd.com/wp-content/resources/56305_SOG_3.00_PUB.pdf>https://developer.amd.com/wp-content/resources/56305_SOG_3.00_PUB.pdf</a>.</p><p>Intel. 2021. <em>Intel® 64 and IA-32 Architectures Software Developer’s
Manual</em>. <a href=https://cdrdv2.intel.com/v1/dl/getContent/671200>https://cdrdv2.intel.com/v1/dl/getContent/671200</a>.</p><p>Kocher, Paul, Jann Horn, Anders Fogh, Daniel Genkin, Daniel Gruss,
Werner Haas, Mike Hamburg, et al. 2019. “Spectre Attacks: Exploiting
Speculative Execution.” In <em>2019 IEEE Symposium on Security and Privacy
(SP)</em>, 1–19. <a href=https://doi.org/10.1109/SP.2019.00002>https://doi.org/10.1109/SP.2019.00002</a>.</p><p>Lipp, Moritz, Daniel Gruss, Raphael Spreitzer, Clémentine Maurice, and
Stefan Mangard. 2016. “ARMageddon: Cache Attacks on Mobile Devices.” In
<em>25th USENIX Security Symposium (USENIX Security 16)</em>, 549–64. Austin,
TX: USENIX Association.
<a href=https://www.usenix.org/conference/usenixsecurity16/technical-sessions/presentation/lipp>https://www.usenix.org/conference/usenixsecurity16/technical-sessions/presentation/lipp</a>.</p><p>Lipp, Moritz, Vedad Hadžić, Michael Schwarz, Arthur Perais, Clémentine
Maurice, and Daniel Gruss. 2020. “Take A Way:
Exploring the Security Implications of AMD’s Cache Way
Predictors.” In <em>15th ACM ASIA Conference on
Computer and Communications Security (ACM ASIACCS 2020)</em>. Taipei,
Taiwan. <a href=https://doi.org/10.1145/3320269.3384746>https://doi.org/10.1145/3320269.3384746</a>.</p><p>Lipp, Moritz, Michael Schwarz, Daniel Gruss, Thomas Prescher, Werner
Haas, Anders Fogh, Jann Horn, et al. 2018. “Meltdown: Reading Kernel
Memory from User Space.” In <em>27th USENIX Security Symposium (USENIX
Security 18)</em>, 973–90. Baltimore, MD: USENIX Association.
<a href=https://www.usenix.org/conference/usenixsecurity18/presentation/lipp>https://www.usenix.org/conference/usenixsecurity18/presentation/lipp</a>.</p><p>Yarom, Yuval, and Katrina Falkner. 2014. “FLUSH+RELOAD: A High
Resolution, Low Noise, L3 Cache Side-Channel Attack.” In <em>23rd USENIX
Security Symposium (USENIX Security 14)</em>, 719–32. San Diego, CA: USENIX
Association.
<a href=https://www.usenix.org/conference/usenixsecurity14/technical-sessions/presentation/yarom>https://www.usenix.org/conference/usenixsecurity14/technical-sessions/presentation/yarom</a>.</p></div><footer class=post-footer><ul class=post-tags></ul><ul class=share-buttons><li><a target=_blank rel="noopener noreferrer" aria-label="share Load+Reload: Uma prova de conceito de um side-channel que explora a cache associativa de processadores AMD on x" href="https://x.com/intent/tweet/?text=Load%2bReload%3a%20Uma%20prova%20de%20conceito%20de%20um%20side-channel%20que%20explora%20a%20cache%20associativa%20de%20processadores%20AMD&amp;url=http%3a%2f%2flocalhost%3a1313%2f2022-10-02-load%2breload%2f&amp;hashtags="><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446C483.971.0 512 28.03 512 62.554zM269.951 190.75 182.567 75.216H56L207.216 272.95 63.9 436.783h61.366L235.9 310.383l96.667 126.4H456L298.367 228.367l134-153.151H371.033zM127.633 110h36.468l219.38 290.065H349.5z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Load+Reload: Uma prova de conceito de um side-channel que explora a cache associativa de processadores AMD on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=http%3a%2f%2flocalhost%3a1313%2f2022-10-02-load%2breload%2f&amp;title=Load%2bReload%3a%20Uma%20prova%20de%20conceito%20de%20um%20side-channel%20que%20explora%20a%20cache%20associativa%20de%20processadores%20AMD&amp;summary=Load%2bReload%3a%20Uma%20prova%20de%20conceito%20de%20um%20side-channel%20que%20explora%20a%20cache%20associativa%20de%20processadores%20AMD&amp;source=http%3a%2f%2flocalhost%3a1313%2f2022-10-02-load%2breload%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Load+Reload: Uma prova de conceito de um side-channel que explora a cache associativa de processadores AMD on reddit" href="https://reddit.com/submit?url=http%3a%2f%2flocalhost%3a1313%2f2022-10-02-load%2breload%2f&title=Load%2bReload%3a%20Uma%20prova%20de%20conceito%20de%20um%20side-channel%20que%20explora%20a%20cache%20associativa%20de%20processadores%20AMD"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Load+Reload: Uma prova de conceito de um side-channel que explora a cache associativa de processadores AMD on facebook" href="https://facebook.com/sharer/sharer.php?u=http%3a%2f%2flocalhost%3a1313%2f2022-10-02-load%2breload%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Load+Reload: Uma prova de conceito de um side-channel que explora a cache associativa de processadores AMD on whatsapp" href="https://api.whatsapp.com/send?text=Load%2bReload%3a%20Uma%20prova%20de%20conceito%20de%20um%20side-channel%20que%20explora%20a%20cache%20associativa%20de%20processadores%20AMD%20-%20http%3a%2f%2flocalhost%3a1313%2f2022-10-02-load%2breload%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Load+Reload: Uma prova de conceito de um side-channel que explora a cache associativa de processadores AMD on telegram" href="https://telegram.me/share/url?text=Load%2bReload%3a%20Uma%20prova%20de%20conceito%20de%20um%20side-channel%20que%20explora%20a%20cache%20associativa%20de%20processadores%20AMD&amp;url=http%3a%2f%2flocalhost%3a1313%2f2022-10-02-load%2breload%2f"><svg viewBox="2 2 28 28" height="30" width="30" fill="currentcolor"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Load+Reload: Uma prova de conceito de um side-channel que explora a cache associativa de processadores AMD on ycombinator" href="https://news.ycombinator.com/submitlink?t=Load%2bReload%3a%20Uma%20prova%20de%20conceito%20de%20um%20side-channel%20que%20explora%20a%20cache%20associativa%20de%20processadores%20AMD&u=http%3a%2f%2flocalhost%3a1313%2f2022-10-02-load%2breload%2f"><svg width="30" height="30" viewBox="0 0 512 512" fill="currentcolor" xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape"><path d="M449.446.0C483.971.0 512 28.03 512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446zM183.8767 87.9921h-62.034L230.6673 292.4508V424.0079h50.6655V292.4508L390.1575 87.9921H328.1233L256 238.2489z"/></svg></a></li></ul></footer></article></main><footer class=footer><span>&copy; 2025 <a href=http://localhost:1313/>Blog do GRIS</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>